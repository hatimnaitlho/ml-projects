{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spam_detection_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNyMVguXy1WTUY2165XHBKq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hatimnaitlho/ml-sklearn/blob/master/spam_detection_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFtVvYz6zmJv",
        "colab_type": "text"
      },
      "source": [
        "# Project overview and scope\n",
        "\n",
        "One of the basic and popular tasks in supervised learning is the classification of data (images or texts). \n",
        "\n",
        "In this notebook, we will use Scikit-learn library to build an SMS spam detector based on the text of the SMS.\n",
        "\n",
        "The Basic Machine learning algorithm for SMS-spam detection will be able to perform the following tasks:\n",
        "- Collect data and preprocess it (vectorizing non numerical data)\n",
        "- Divide data-set to training and test sets\n",
        "- Build classifiers and training them\n",
        "- Assess the performance of each classifier (precision, recall)\n",
        "- Find classifiers with higher performance (precision and recall)\n",
        "\n",
        "Note: the tuning of algorithms hyperparameters is outside the scope of this notebook. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYiELBaE2SAr",
        "colab_type": "text"
      },
      "source": [
        "# The data collection\n",
        "\n",
        "We will be using a [dataset](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection) from the UCI Machine Learning repository. This collection of 5,574 labeled SMS messages have been collected for mobile phone spam research.. \n",
        "\n",
        "The collection is composed by just one text file, where each line has the correct class (spam or ham) followed by the raw message.\n",
        "\n",
        "The direct data link is [here](https://archive.ics.uci.edu/ml/machine-learning-databases/00228/).\n",
        "\n",
        "For this project, we will use Scikit-learn library which contains various classification, regression and clustering algorithms and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZGc33kfzK30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import libraries\n",
        "import numpy as np \n",
        "import pandas as pd \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5BErshq9jiA",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Data collection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmojtyB-x5Q5",
        "colab_type": "code",
        "outputId": "2354177a-bce1-4a9c-b4e0-51b8c6b165c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "# Load the SMS-spam dataset\n",
        "url_dataset= 'https://raw.githubusercontent.com/hatimnaitlho/ml-sklearn/master/datasets/smsspamcollection/SMSSpamCollection'\n",
        "df = pd.read_table(url_dataset, sep='\\t', names=['label', 'sms_message'])\n",
        "\n",
        "# Output printing out first 5 rows\n",
        "df.head()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sms_message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                        sms_message\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRejQDsoAwX2",
        "colab_type": "code",
        "outputId": "1ae36b12-c9fd-4c2b-ce35-78e8eac0b398",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5572, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cakQ7EtxArMf",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "Since Scikit-learn only deals with numerical values, we have to convert our categorical values to numerical ones. For that we will do some data preprocessing.\n",
        "\n",
        "For labels, the solution is easy, and we have only to transform 'spam' on 1, and ham on 0.\n",
        "\n",
        "The sms_message which is in the plain text format that contains all needed information (features) for classification purpose. We will then have to build our feature vector from plain text.\n",
        "\n",
        "For this, scikit-learn has powerful vectorizers such as CountVectorizer, TfidfVectorizer, HashingVectorizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6S3mLcKA0AI",
        "colab_type": "code",
        "outputId": "7a1e03d0-e2cb-4e43-8ab0-17a6b967983c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "df.groupby('label').count()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sms_message</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ham</th>\n",
              "      <td>4825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spam</th>\n",
              "      <td>747</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       sms_message\n",
              "label             \n",
              "ham           4825\n",
              "spam           747"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBZzja1iE69I",
        "colab_type": "code",
        "outputId": "152eaed1-589c-4397-a94a-e4cfac67c0fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "df['label']=df['label'].map({'ham':0, 'spam':1})\n",
        "df.head()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sms_message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                        sms_message\n",
              "0      0  Go until jurong point, crazy.. Available only ...\n",
              "1      0                      Ok lar... Joking wif u oni...\n",
              "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      0  U dun say so early hor... U c already then say...\n",
              "4      0  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jtX1KmI7cXI",
        "colab_type": "text"
      },
      "source": [
        "# Bag of Words (BoW) Implementation\n",
        "\n",
        "What we have here in our data set is a collection of text data (5,572 rows of data). Most ML algorithms rely on numerical data to be fed into them as input, and email/sms messages are usually text heavy.\n",
        "\n",
        "Here we'd like to introduce the Bag of Words(BoW) concept which is a term used to specify the problems that have a 'bag of words' or a collection of text data that needs to be worked with. The basic idea of BoW is to take a piece of text and count the frequency of the words in that text. It is important to note that the BoW concept treats each word individually and the order in which the words occur does not matter.\n",
        "\n",
        "Using a process which we will go through now, we can covert a collection of documents to a matrix, with each document being a row and each word(token) being the column, and the corresponding (row,column) values being the frequency of occurrance of each word or token in that document."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GresqWQJfiO",
        "colab_type": "text"
      },
      "source": [
        "Let's implement the CountVectorizer method in sklearn which provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvW90JhWKhJQ",
        "colab_type": "text"
      },
      "source": [
        "### Implementing CountVectorizer method\n",
        "Let's implement and use CountVectorizer method in a sample documents to understand how it works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRgLvhbVJMoJ",
        "colab_type": "code",
        "outputId": "f746116b-4761-40ea-d39b-0b790e48b182",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# Instantiate the CountVectorizer method\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vector = CountVectorizer(stop_words='english')\n",
        " \n",
        "documents = ['By receiving spam messages', \n",
        "              'Internet users are exposed to security issues',\n",
        "             'and minors are exposed to inappropriate contents.',\n",
        "             'Moreover, spam messages waste resources in terms of:',\n",
        "              'storage, bandwidth, and productivity.',\n",
        "             'What makes the problem worse is that spammers',\n",
        "              'keep inventing new techniques to dodge spam filters.']\n",
        "\n",
        "count_vector.fit(documents)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrM0ehneMPK-",
        "colab_type": "code",
        "outputId": "3dcc005b-d42f-4aeb-f7e7-f3ce7ae8506a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        }
      },
      "source": [
        "count_vector.get_feature_names()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bandwidth',\n",
              " 'contents',\n",
              " 'dodge',\n",
              " 'exposed',\n",
              " 'filters',\n",
              " 'inappropriate',\n",
              " 'internet',\n",
              " 'inventing',\n",
              " 'issues',\n",
              " 'makes',\n",
              " 'messages',\n",
              " 'minors',\n",
              " 'new',\n",
              " 'problem',\n",
              " 'productivity',\n",
              " 'receiving',\n",
              " 'resources',\n",
              " 'security',\n",
              " 'spam',\n",
              " 'spammers',\n",
              " 'storage',\n",
              " 'techniques',\n",
              " 'terms',\n",
              " 'users',\n",
              " 'waste',\n",
              " 'worse']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtM_ewLwMgNC",
        "colab_type": "code",
        "outputId": "8cd239e8-c66f-4bf0-f645-f73a9b436524",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        }
      },
      "source": [
        "doc_array = count_vector.transform(documents).toarray()\n",
        "doc_array"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "        0, 0, 0, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "        0, 1, 0, 0],\n",
              "       [0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "        1, 0, 1, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
              "        0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "        0, 0, 0, 1],\n",
              "       [0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
              "        0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWFCJwBYM4KS",
        "colab_type": "code",
        "outputId": "63063556-7a06-4af1-a46c-0c1441f14ffc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "frequency_matrix = pd.DataFrame(doc_array, \n",
        "                                columns = count_vector.get_feature_names())\n",
        "frequency_matrix"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bandwidth</th>\n",
              "      <th>contents</th>\n",
              "      <th>dodge</th>\n",
              "      <th>exposed</th>\n",
              "      <th>filters</th>\n",
              "      <th>inappropriate</th>\n",
              "      <th>internet</th>\n",
              "      <th>inventing</th>\n",
              "      <th>issues</th>\n",
              "      <th>makes</th>\n",
              "      <th>messages</th>\n",
              "      <th>minors</th>\n",
              "      <th>new</th>\n",
              "      <th>problem</th>\n",
              "      <th>productivity</th>\n",
              "      <th>receiving</th>\n",
              "      <th>resources</th>\n",
              "      <th>security</th>\n",
              "      <th>spam</th>\n",
              "      <th>spammers</th>\n",
              "      <th>storage</th>\n",
              "      <th>techniques</th>\n",
              "      <th>terms</th>\n",
              "      <th>users</th>\n",
              "      <th>waste</th>\n",
              "      <th>worse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   bandwidth  contents  dodge  exposed  ...  terms  users  waste  worse\n",
              "0          0         0      0        0  ...      0      0      0      0\n",
              "1          0         0      0        1  ...      0      1      0      0\n",
              "2          0         1      0        1  ...      0      0      0      0\n",
              "3          0         0      0        0  ...      1      0      1      0\n",
              "4          1         0      0        0  ...      0      0      0      0\n",
              "5          0         0      0        0  ...      0      0      0      1\n",
              "6          0         0      1        0  ...      0      0      0      0\n",
              "\n",
              "[7 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1ziA6-JLTXQ",
        "colab_type": "text"
      },
      "source": [
        "# Building Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8HVsBqKxMOE",
        "colab_type": "text"
      },
      "source": [
        "#### Let's separate our dataset into a training and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aM3j3Xq9O7-z",
        "colab_type": "code",
        "outputId": "9a391578-573c-4fbc-e871-f5b1cbc6c9dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['sms_message'], df['label'], test_size=0.25, random_state=42)\n",
        "print('Number of rows in the total set: {}'.format(df.shape[0]))\n",
        "print('Number of rows in the training set: {}'.format(X_train.shape[0]))\n",
        "print('Number of rows in the test set: {}'.format(X_test.shape[0]))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of rows in the total set: 5572\n",
            "Number of rows in the training set: 4179\n",
            "Number of rows in the test set: 1393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SUXoUIdQcEF",
        "colab_type": "text"
      },
      "source": [
        "#### Applying Bag of Words processing\n",
        "\n",
        "This preprocessing step will transform the plain text (sms_message), and extract numerical features using the Bag of Words concept."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AihCLR0LQgjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate the CountVectorizer method\n",
        "count_vector = CountVectorizer(stop_words='english')\n",
        "\n",
        "# Fit the training data and then return the matrix\n",
        "training_data = count_vector.fit_transform(X_train)\n",
        "\n",
        "# Transform testing data and return the matrix. Note we are not fitting the testing data into the CountVectorizer()\n",
        "testing_data = count_vector.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDVo3Tq_8HJv",
        "colab_type": "text"
      },
      "source": [
        "## Accuracy vs. Recall vs. Precision\n",
        "\n",
        "Choosing the right performance metric is critical in machine learning projects, and allow to reach the best model according to the business need.\n",
        "\n",
        "Accuracy is not perinent in our case (spam detection classifier). Therefore, we will use Precision and recall:\n",
        "- The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
        "\n",
        "- Recall is The recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.\n",
        "\n",
        "Precision answers the question \"If the spam classifies an SMS or email as spam, what’s the probability that it’s really a spam?\" as defined earlier. Thus, the spam classifier must have high precision, which prevent labeling ham messages as spam and loosing them in the \"junk folder\".\n",
        "\n",
        "Recall, answers the following question \"Of all the spam in the sms/email set, what proportion does the spam classifier detect?”. Thus, recall is less important than precision in this specific case, and will result on spam messages not detected, which will be annoying, but not as critical as loosing non-spam messages.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EO2gvgDn1QD9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "5fbc63a7-286f-4b54-9612-835b828748e5"
      },
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.linear_model import RidgeClassifierCV\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.metrics import precision_score \n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "l1, l2, l3, l4 =([] for i in range(4))\n",
        "metrics_dict = {}\n",
        "classifiers= [\n",
        "        BernoulliNB(),\n",
        "        RandomForestClassifier(),\n",
        "        AdaBoostClassifier(),\n",
        "        BaggingClassifier(),\n",
        "        ExtraTreesClassifier(),\n",
        "        GradientBoostingClassifier(),\n",
        "        DecisionTreeClassifier(),\n",
        "        LogisticRegression(),\n",
        "        RidgeClassifier(),\n",
        "        RidgeClassifierCV(),\n",
        "        SGDClassifier(),\n",
        "        OneVsRestClassifier(SVC()),\n",
        "        KNeighborsClassifier()\n",
        "    ]\n",
        "\n",
        "for clf in classifiers:\n",
        "  clf.fit(training_data, y_train)\n",
        "  clf.predict(testing_data)\n",
        "  name= clf.__class__.__name__\n",
        "  l1.append(name)\n",
        "  metrics_dict['model']= l1\n",
        "  l2.append(precision_score(y_test, clf.predict(testing_data)))\n",
        "  metrics_dict['precision_score']= l2\n",
        "  l3.append(recall_score(y_test, clf.predict(testing_data)))\n",
        "  metrics_dict['recall_score'] = l3\n",
        "  l4.append(f1_score(y_test, clf.predict(testing_data)))\n",
        "  metrics_dict['f1_score'] = l4\n",
        " \n",
        "\n",
        "\n",
        "df = pd.DataFrame(metrics_dict)\n",
        "df\n",
        "\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>precision_score</th>\n",
              "      <th>recall_score</th>\n",
              "      <th>f1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BernoulliNB</td>\n",
              "      <td>0.993377</td>\n",
              "      <td>0.806452</td>\n",
              "      <td>0.890208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.838710</td>\n",
              "      <td>0.912281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>0.958580</td>\n",
              "      <td>0.870968</td>\n",
              "      <td>0.912676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BaggingClassifier</td>\n",
              "      <td>0.956522</td>\n",
              "      <td>0.827957</td>\n",
              "      <td>0.887608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ExtraTreesClassifier</td>\n",
              "      <td>0.987654</td>\n",
              "      <td>0.860215</td>\n",
              "      <td>0.919540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.992908</td>\n",
              "      <td>0.752688</td>\n",
              "      <td>0.856269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>0.934524</td>\n",
              "      <td>0.844086</td>\n",
              "      <td>0.887006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.860215</td>\n",
              "      <td>0.924855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RidgeClassifier</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.849462</td>\n",
              "      <td>0.918605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RidgeClassifierCV</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.849462</td>\n",
              "      <td>0.918605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>SGDClassifier</td>\n",
              "      <td>0.994012</td>\n",
              "      <td>0.892473</td>\n",
              "      <td>0.940510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>OneVsRestClassifier</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.876344</td>\n",
              "      <td>0.934097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.360215</td>\n",
              "      <td>0.529644</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         model  precision_score  recall_score  f1_score\n",
              "0                  BernoulliNB         0.993377      0.806452  0.890208\n",
              "1       RandomForestClassifier         1.000000      0.838710  0.912281\n",
              "2           AdaBoostClassifier         0.958580      0.870968  0.912676\n",
              "3            BaggingClassifier         0.956522      0.827957  0.887608\n",
              "4         ExtraTreesClassifier         0.987654      0.860215  0.919540\n",
              "5   GradientBoostingClassifier         0.992908      0.752688  0.856269\n",
              "6       DecisionTreeClassifier         0.934524      0.844086  0.887006\n",
              "7           LogisticRegression         1.000000      0.860215  0.924855\n",
              "8              RidgeClassifier         1.000000      0.849462  0.918605\n",
              "9            RidgeClassifierCV         1.000000      0.849462  0.918605\n",
              "10               SGDClassifier         0.994012      0.892473  0.940510\n",
              "11         OneVsRestClassifier         1.000000      0.876344  0.934097\n",
              "12        KNeighborsClassifier         1.000000      0.360215  0.529644"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wj15BmF3InjD",
        "colab_type": "text"
      },
      "source": [
        "## The Confusion matrix\n",
        "\n",
        "![alt text](https://miro.medium.com/max/1166/0*2ICu3zRUHkFvzxx7.png)\n",
        "\n",
        "Let's campare two classifiers the KNeighborsClassifier, and the OneVsRestClassifier. They both have nearly the same precision (=1), meaning that every message labeled as spam is really spam. However, they have different recall scores.\n",
        "- The recall_score(KNeighborsClassifier)= 0.360215 while, \n",
        "- The recall_score(OneVsRestClassifier)=0.876344\n",
        "\n",
        "meaning that the OneVsRestClassifier will outperform in term of filtering more spam messages compared to the KNeighborsClassifier as we will see using the confusion matrix.\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-CEwbtSkNPP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "9e355796-c5f1-4c69-9d9a-44842f5cd18f"
      },
      "source": [
        "y_test.value_counts()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1207\n",
              "1     186\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CghOF_h6YLkw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "26d2fe19-6a9b-4483-bc5a-f492e078a545"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knclf= KNeighborsClassifier()\n",
        "knclf.fit(training_data, y_train)\n",
        "\n",
        "y_pred_kn= knclf.predict(testing_data)\n",
        "\n",
        "print(\"The confusion matrix of the KNeighborsClassifier: \")\n",
        "display(confusion_matrix(y_test, y_pred_kn, labels=[1,0]))\n",
        "print('\\n')\n",
        "print('The number of non-spam messages labelled as spam is {}'.format(confusion_matrix(y_test, y_pred_kn)[0,1]))\n",
        "print('The number of spam messages not detected by the classifier {}'.format(confusion_matrix(y_test, y_pred_kn)[1,0]))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The confusion matrix of the KNeighborsClassifier: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[  67,  119],\n",
              "       [   0, 1207]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "The number of non-spam messages labelled as spam is 0\n",
            "The number of spam messages not detected by the classifier 119\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maoEMHhVb5e4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "b8e8ab2d-6263-41b4-981c-ce0d9eed0945"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "clf_ovs= OneVsRestClassifier(SVC())\n",
        "clf_ovs.fit(training_data, y_train)\n",
        "y_pred_ovs= clf_ovs.predict(testing_data)\n",
        "print(\"The confusion matrix of the OneVsRestClassifier: \")\n",
        "display(confusion_matrix(y_test, y_pred_ovs, labels=[1,0]))\n",
        "print('\\n')\n",
        "print('The number of non-spam messages labelled as spam is {}'.format(confusion_matrix(y_test, y_pred_ovs)[0,1]))\n",
        "print('The number of spam messages not detected by the classifier  {}'.format(confusion_matrix(y_test, y_pred_ovs)[1,0]))\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The confusion matrix of the OneVsRestClassifier: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[ 163,   23],\n",
              "       [   0, 1207]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "The number of non-spam messages labelled as spam is 0\n",
            "The number of spam messages not detected by the classifier  23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Plvvvx047cwm",
        "colab_type": "text"
      },
      "source": [
        "Note: We used default hyperparameters for each classifier, meaning that we have at this stage to choose the most permant classifiers to focus on, and then tune hyperparameters, using some ML techniques."
      ]
    }
  ]
}